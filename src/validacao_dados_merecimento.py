# Databricks notebook source
# MAGIC %md
# MAGIC # ValidaÃ§Ã£o dos Dados - PreparaÃ§Ã£o de Tabelas
# MAGIC 
# MAGIC Este notebook valida os resultados da preparaÃ§Ã£o das tabelas de matriz de merecimento,
# MAGIC gerando relatÃ³rios de qualidade dos dados para anÃ¡lise.
# MAGIC 
# MAGIC **Objetivo**: Verificar se os nÃºmeros fazem sentido e identificar possÃ­veis problemas nos dados.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Imports e ConfiguraÃ§Ã£o

# COMMAND ----------

from pyspark.sql import functions as F
from pyspark.sql.window import Window
from datetime import datetime, timedelta
import json

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento dos Dados

# MAGIC %md
# MAGIC Carregamos a tabela de merecimento para validaÃ§Ã£o
# MAGIC e anÃ¡lise de qualidade dos dados.

# COMMAND ----------

# Carregar dados da tabela de merecimento
df_merecimento = spark.table('databox.bcg_comum.supply_base_merecimento_diario')

print(f"âœ… Dados carregados com sucesso!")
print(f"ğŸ“Š Total de registros: {df_merecimento.count():,}")
print(f"ğŸ“‹ Total de colunas: {len(df_merecimento.columns)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. InformaÃ§Ãµes BÃ¡sicas do Dataset

# MAGIC %md
# MAGIC Analisamos as informaÃ§Ãµes bÃ¡sicas do dataset para entender
# MAGIC a estrutura e perÃ­odo dos dados.

# COMMAND ----------

# InformaÃ§Ãµes bÃ¡sicas
total_rows = df_merecimento.count()
total_columns = len(df_merecimento.columns)

# PerÃ­odo dos dados
date_range = df_merecimento.agg(
    F.min("DtAtual").alias("data_min"),
    F.max("DtAtual").alias("data_max")
).collect()[0]

print("ğŸ” INFORMAÃ‡Ã•ES BÃSICAS DO DATASET")
print("=" * 50)
print(f"ğŸ“ˆ Total de registros: {total_rows:,}")
print(f"ğŸ“‹ Total de colunas: {total_columns}")
print(f"ğŸ“… PerÃ­odo: {date_range['data_min']} a {date_range['data_max']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Contagem de Entidades Distintas

# MAGIC %md
# MAGIC Contamos as entidades distintas para verificar a cobertura
# MAGIC dos dados por filial, SKU e classificaÃ§Ãµes.

# COMMAND ----------

# Contagem de entidades distintas
distinct_counts = df_merecimento.agg(
    F.countDistinct("CdFilial").alias("filiais_distintas"),
    F.countDistinct("CdSku").alias("skus_distintos"),
    F.countDistinct("DsSetor").alias("setores_distintos"),
    F.countDistinct("DsCurva").alias("curvas_distintas"),
    F.countDistinct("DsCurvaAbcLoja").alias("curvas_abc_distintas")
).collect()[0]

print("ğŸ¢ CONTAGEM DE ENTIDADES DISTINTAS")
print("=" * 50)
print(f"ğŸª Filiais distintas: {distinct_counts['filiais_distintas']}")
print(f"ğŸ“¦ SKUs distintos: {distinct_counts['skus_distintos']}")
print(f"ğŸ­ Setores distintos: {distinct_counts['setores_distintas']}")
print(f"ğŸ“Š Curvas distintas: {distinct_counts['curvas_distintas']}")
print(f"ğŸ“Š Curvas ABC distintas: {distinct_counts['curvas_abc_distintas']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. AnÃ¡lise de Campos Nulos

# MAGIC %md
# MAGIC Verificamos a presenÃ§a de campos nulos para identificar
# MAGIC possÃ­veis problemas de qualidade dos dados.

# COMMAND ----------

print("âŒ ANÃLISE DE CAMPOS NULOS")
print("=" * 50)

null_counts = {}
for col in df_merecimento.columns:
    null_count = df_merecimento.filter(F.col(col).isNull()).count()
    null_percentage = (null_count / total_rows) * 100
    null_counts[col] = {"count": null_count, "percentage": null_percentage}
    
    if null_count > 0:
        print(f"âš ï¸ {col}: {null_count:,} nulos ({null_percentage:.2f}%)")
    else:
        print(f"âœ… {col}: Sem nulos")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. DistribuiÃ§Ã£o de Dias por Filial e SKU

# MAGIC %md
# MAGIC Analisamos a distribuiÃ§Ã£o de dias por filial e SKU para verificar
# MAGIC a consistÃªncia temporal dos dados.

# COMMAND ----------

# DistribuiÃ§Ã£o de dias por filial e SKU
days_per_filial_sku = df_merecimento.groupBy("CdFilial", "CdSku").agg(
    F.count("DtAtual").alias("dias_com_dados")
).orderBy("dias_com_dados", ascending=False)

# EstatÃ­sticas da distribuiÃ§Ã£o
days_stats = days_per_filial_sku.agg(
    F.min("dias_com_dados").alias("min_dias"),
    F.max("dias_com_dados").alias("max_dias"),
    F.avg("dias_com_dados").alias("avg_dias"),
    F.stddev("dias_com_dados").alias("std_dias")
).collect()[0]

print("ğŸ“… DISTRIBUIÃ‡ÃƒO DE DIAS POR FILIAL E SKU")
print("=" * 50)
print(f"ğŸ“Š MÃ­nimo de dias por filial/SKU: {days_stats['min_dias']}")
print(f"ğŸ“Š MÃ¡ximo de dias por filial/SKU: {days_stats['max_dias']}")
print(f"ğŸ“Š MÃ©dia de dias por filial/SKU: {days_stats['avg_dias']:.2f}")
print(f"ğŸ“Š Desvio padrÃ£o: {days_stats['std_dias']:.2f}" if days_stats['std_dias'] else "ğŸ“Š Desvio padrÃ£o: N/A")

# Mostrar top 10 combinaÃ§Ãµes filial/SKU com mais dias
print("\nğŸ† TOP 10 - Filiais/SKUs com mais dias de dados:")
display(days_per_filial_sku.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Quantidade de SKUs por Filial

# MAGIC %md
# MAGIC Analisamos a quantidade de SKUs por filial para verificar
# MAGIC a distribuiÃ§Ã£o de produtos entre as lojas.

# COMMAND ----------

# Quantidade de SKUs por filial
skus_per_filial = df_merecimento.groupBy("CdFilial").agg(
    F.countDistinct("CdSku").alias("skus_por_filial")
).orderBy("skus_por_filial", ascending=False)

# EstatÃ­sticas da distribuiÃ§Ã£o
skus_stats = skus_per_filial.agg(
    F.min("skus_por_filial").alias("min_skus"),
    F.max("skus_por_filial").alias("max_skus"),
    F.avg("skus_por_filial").alias("avg_skus"),
    F.stddev("skus_por_filial").alias("std_skus")
).collect()[0]

print("ğŸª QUANTIDADE DE SKUs POR FILIAL")
print("=" * 50)
print(f"ğŸ“¦ MÃ­nimo de SKUs por filial: {skus_stats['min_skus']}")
print(f"ğŸ“¦ MÃ¡ximo de SKUs por filial: {skus_stats['max_skus']}")
print(f"ğŸ“¦ MÃ©dia de SKUs por filial: {skus_stats['avg_skus']:.2f}")
print(f"ğŸ“¦ Desvio padrÃ£o: {skus_stats['std_skus']:.2f}" if skus_stats['std_skus'] else "ğŸ“¦ Desvio padrÃ£o: N/A")

# Mostrar top 10 filiais com mais SKUs
print("\nğŸ† TOP 10 - Filiais com mais SKUs:")
display(skus_per_filial.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. AnÃ¡lise de MÃ©tricas de NegÃ³cio

# MAGIC %md
# MAGIC Analisamos as mÃ©tricas de negÃ³cio para verificar
# MAGIC a consistÃªncia dos valores calculados.

# COMMAND ----------

# MÃ©tricas de negÃ³cio
business_metrics = df_merecimento.agg(
    F.sum("EstoqueLoja").alias("total_estoque"),
    F.sum("Receita").alias("total_receita"),
    F.sum("QtMercadoria").alias("total_vendas"),
    F.sum("FlagRuptura").alias("total_rupturas"),
    F.sum("ReceitaPerdidaRuptura").alias("receita_perdida_total")
).collect()[0]

print("ğŸ’° ANÃLISE DE MÃ‰TRICAS DE NEGÃ“CIO")
print("=" * 50)
print(f"ğŸ“¦ Total de estoque: {business_metrics['total_estoque']:,}")
print(f"ğŸ’° Total de receita: R$ {business_metrics['total_receita']:,.2f}")
print(f"ğŸ›’ Total de vendas: {business_metrics['total_vendas']:,}")
print(f"âš ï¸ Total de rupturas: {business_metrics['total_rupturas']:,}")
print(f"ğŸ’¸ Receita perdida por ruptura: R$ {business_metrics['receita_perdida_total']:,.2f}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. VerificaÃ§Ãµes de Qualidade

# MAGIC %md
# MAGIC Realizamos verificaÃ§Ãµes especÃ­ficas de qualidade para identificar
# MAGIC possÃ­veis inconsistÃªncias nos dados.

# COMMAND ----------

print("ğŸ” VERIFICAÃ‡Ã•ES DE QUALIDADE")
print("=" * 50)

# Verificar valores negativos
negative_estoque = df_merecimento.filter(F.col("EstoqueLoja") < 0).count()
negative_receita = df_merecimento.filter(F.col("Receita") < 0).count()
negative_vendas = df_merecimento.filter(F.col("QtMercadoria") < 0).count()

print(f"ğŸ“¦ Estoque negativo: {negative_estoque} registros")
print(f"ğŸ’° Receita negativa: {negative_receita} registros")
print(f"ğŸ›’ Vendas negativas: {negative_vendas} registros")

# Verificar datas invÃ¡lidas
invalid_dates = df_merecimento.filter(
    (F.col("DtAtual").isNull()) |
    (F.col("DtAtual") < "2020-01-01") |
    (F.col("DtAtual") > "2030-12-31")
).count()

print(f"ğŸ“… Datas invÃ¡lidas: {invalid_dates} registros")

# Verificar mÃ©dias mÃ³veis invÃ¡lidas
invalid_media = df_merecimento.filter(
    (F.col("Media90_Qt_venda_estq") < 0)
).count()

print(f"âœ… MÃ©dias mÃ³veis invÃ¡lidas: {invalid_media} registros")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. AnÃ¡lise de Rupturas

# MAGIC %md
# MAGIC Analisamos detalhadamente as rupturas para entender
# MAGIC o impacto no negÃ³cio e identificar padrÃµes.

# COMMAND ----------

# AnÃ¡lise detalhada de rupturas
ruptura_analysis = df_merecimento.filter(F.col("FlagRuptura") == 1).agg(
    F.count("*").alias("total_rupturas"),
    F.sum("deltaRuptura").alias("total_delta_ruptura"),
    F.sum("ReceitaPerdidaRuptura").alias("total_receita_perdida"),
    F.avg("deltaRuptura").alias("media_delta_ruptura"),
    F.avg("ReceitaPerdidaRuptura").alias("media_receita_perdida")
).collect()[0]

print("âš ï¸ ANÃLISE DE RUPTURAS")
print("=" * 50)
print(f"ğŸ“Š Total de rupturas: {ruptura_analysis['total_rupturas']:,}")
print(f"ğŸ“Š Total de delta de ruptura: {ruptura_analysis['total_delta_ruptura']:,.0f}")
print(f"ğŸ’° Total de receita perdida: R$ {ruptura_analysis['total_receita_perdida']:,.2f}")
print(f"ğŸ“Š MÃ©dia de delta de ruptura: {ruptura_analysis['media_delta_ruptura']:,.2f}")
print(f"ğŸ’° MÃ©dia de receita perdida: R$ {ruptura_analysis['media_receita_perdida']:,.2f}")

# Top 10 rupturas por receita perdida
print("\nğŸ† TOP 10 - Rupturas com maior receita perdida:")
top_rupturas = df_merecimento.filter(F.col("FlagRuptura") == 1) \
    .select("DtAtual", "CdFilial", "CdSku", "DsSku", "EstoqueLoja", 
            "Media90_Qt_venda_estq", "deltaRuptura", "ReceitaPerdidaRuptura") \
    .orderBy(F.col("ReceitaPerdidaRuptura").desc()) \
    .limit(10)

display(top_rupturas)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 9. DistribuiÃ§Ã£o por Setor e Curva

# MAGIC %md
# MAGIC Analisamos a distribuiÃ§Ã£o dos dados por setor e curva
# MAGIC para verificar a representatividade das classificaÃ§Ãµes.

# COMMAND ----------

# DistribuiÃ§Ã£o por setor
setor_distribution = df_merecimento.groupBy("DsSetor").agg(
    F.count("*").alias("total_registros"),
    F.countDistinct("CdFilial").alias("filiais_distintas"),
    F.countDistinct("CdSku").alias("skus_distintos"),
    F.sum("EstoqueLoja").alias("total_estoque"),
    F.sum("Receita").alias("total_receita")
).orderBy("total_registros", ascending=False)

print("ğŸ­ DISTRIBUIÃ‡ÃƒO POR SETOR")
print("=" * 50)
display(setor_distribution)

# DistribuiÃ§Ã£o por curva
curva_distribution = df_merecimento.groupBy("DsCurva").agg(
    F.count("*").alias("total_registros"),
    F.countDistinct("CdFilial").alias("filiais_distintas"),
    F.countDistinct("CdSku").alias("skus_distintos"),
    F.sum("EstoqueLoja").alias("total_estoque"),
    F.sum("Receita").alias("total_receita")
).orderBy("total_registros", ascending=False)

print("ğŸ“Š DISTRIBUIÃ‡ÃƒO POR CURVA")
print("=" * 50)
display(curva_distribution)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 10. Resumo Executivo

# MAGIC %md
# MAGIC Apresentamos um resumo executivo da validaÃ§Ã£o com
# MAGIC score de qualidade e recomendaÃ§Ãµes.

# COMMAND ----------

# Calcular score de qualidade (0-100)
quality_score = 100

# Penalizar por campos nulos
total_null_fields = sum(1 for col_data in null_counts.values() if col_data["count"] > 0)
if total_null_fields > 0:
    quality_score -= min(20, total_null_fields * 2)

# Penalizar por valores negativos
total_negative = negative_estoque + negative_receita + negative_vendas
if total_negative > 0:
    quality_score -= min(15, total_negative * 3)

# Penalizar por inconsistÃªncias de data
if invalid_dates > 0:
    quality_score -= min(10, invalid_dates * 2)

print("ğŸ“‹ RESUMO EXECUTIVO")
print("=" * 50)

if quality_score >= 90:
    print("ğŸŸ¢ QUALIDADE EXCELENTE")
elif quality_score >= 80:
    print("ğŸŸ¡ QUALIDADE BOA")
elif quality_score >= 70:
    print("ğŸŸ  QUALIDADE REGULAR")
else:
    print("ğŸ”´ QUALIDADE CRÃTICA")

print(f"ğŸ“Š Score de qualidade: {quality_score}/100")

print(f"\nğŸ“ˆ Total de registros: {total_rows:,}")
print(f"ğŸª Total de filiais: {distinct_counts['filiais_distintas']}")
print(f"ğŸ“¦ Total de SKUs: {distinct_counts['skus_distintos']}")
print(f"âš ï¸ Total de rupturas: {business_metrics['total_rupturas']:,}")

print(f"\nğŸ” PROBLEMAS IDENTIFICADOS:")
if total_null_fields > 0:
    print(f"  â€¢ {total_null_fields} campos com valores nulos")
if total_negative > 0:
    print(f"  â€¢ {total_negative} registros com valores negativos")
if invalid_dates > 0:
    print(f"  â€¢ {invalid_dates} registros com datas invÃ¡lidas")

print(f"\nâœ… RECOMENDAÃ‡Ã•ES:")
if quality_score >= 90:
    print("  â€¢ Dados prontos para uso em anÃ¡lises")
elif quality_score >= 80:
    print("  â€¢ Pequenos ajustes recomendados antes do uso")
elif quality_score >= 70:
    print("  â€¢ RevisÃ£o moderada necessÃ¡ria")
else:
    print("  â€¢ RevisÃ£o urgente necessÃ¡ria antes do uso")

print(f"\nğŸ¯ PrÃ³ximos passos: Executar notebook de anÃ¡lise da matriz de merecimento")
