# Databricks notebook source
# MAGIC %md
# MAGIC # ValidaÃ§Ã£o dos Dados - PreparaÃ§Ã£o de Tabelas
# MAGIC 
# MAGIC Este notebook valida os resultados da preparaÃ§Ã£o das tabelas de matriz de merecimento,
# MAGIC gerando relatÃ³rios de qualidade dos dados para anÃ¡lise.
# MAGIC 
# MAGIC **Objetivo**: Verificar se os nÃºmeros fazem sentido e identificar possÃ­veis problemas nos dados.

# COMMAND ----------

# MAGIC %md
# MAGIC ## Imports e ConfiguraÃ§Ã£o

# COMMAND ----------

from pyspark.sql import functions as F
from pyspark.sql.window import Window
from datetime import datetime, timedelta
import json

# COMMAND ----------

# MAGIC %md
# MAGIC ## Carregamento dos Dados

# COMMAND ----------

# Carregar dados da tabela de merecimento
df_merecimento = spark.table('databox.bcg_comum.supply_base_merecimento_diario')

print(f"âœ… Dados carregados com sucesso!")
print(f"ğŸ“Š Total de registros: {df_merecimento.count():,}")
print(f"ğŸ“‹ Total de colunas: {len(df_merecimento.columns)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. InformaÃ§Ãµes BÃ¡sicas do Dataset

# COMMAND ----------

# InformaÃ§Ãµes bÃ¡sicas
total_rows = df_merecimento.count()
total_columns = len(df_merecimento.columns)

# PerÃ­odo dos dados
date_range = df_merecimento.agg(
    F.min("DtAtual").alias("data_min"),
    F.max("DtAtual").alias("data_max")
).collect()[0]

print("ğŸ” INFORMAÃ‡Ã•ES BÃSICAS DO DATASET")
print("=" * 50)
print(f"ğŸ“ˆ Total de registros: {total_rows:,}")
print(f"ğŸ“‹ Total de colunas: {total_columns}")
print(f"ğŸ“… PerÃ­odo: {date_range['data_min']} a {date_range['data_max']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Contagem de Entidades Distintas

# COMMAND ----------

# Contagem de entidades distintas
distinct_counts = df_merecimento.agg(
    F.countDistinct("CdFilial").alias("filiais_distintas"),
    F.countDistinct("CdSku").alias("skus_distintos"),
    F.countDistinct("DsSetor").alias("setores_distintos"),
    F.countDistinct("DsCurva").alias("curvas_distintas"),
    F.countDistinct("DsCurvaAbcLoja").alias("curvas_abc_distintas")
).collect()[0]

print("ğŸ¢ CONTAGEM DE ENTIDADES DISTINTAS")
print("=" * 50)
print(f"ğŸª Filiais distintas: {distinct_counts['filiais_distintas']}")
print(f"ğŸ“¦ SKUs distintos: {distinct_counts['skus_distintos']}")
print(f"ğŸ­ Setores distintos: {distinct_counts['setores_distintos']}")
print(f"ğŸ“Š Curvas distintas: {distinct_counts['curvas_distintas']}")
print(f"ğŸ“Š Curvas ABC distintas: {distinct_counts['curvas_abc_distintas']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. AnÃ¡lise de Campos Nulos

# COMMAND ----------

print("âŒ ANÃLISE DE CAMPOS NULOS")
print("=" * 50)

null_counts = {}
for col in df_merecimento.columns:
    null_count = df_merecimento.filter(F.col(col).isNull()).count()
    null_percentage = (null_count / total_rows) * 100
    null_counts[col] = {"count": null_count, "percentage": null_percentage}
    
    if null_count > 0:
        print(f"âš ï¸ {col}: {null_count:,} nulos ({null_percentage:.2f}%)")
    else:
        print(f"âœ… {col}: Sem nulos")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. DistribuiÃ§Ã£o de Dias por Filial e SKU

# COMMAND ----------

# DistribuiÃ§Ã£o de dias por filial e SKU
days_per_filial_sku = df_merecimento.groupBy("CdFilial", "CdSku").agg(
    F.count("DtAtual").alias("dias_com_dados")
).orderBy("dias_com_dados", ascending=False)

# EstatÃ­sticas da distribuiÃ§Ã£o
days_stats = days_per_filial_sku.agg(
    F.min("dias_com_dados").alias("min_dias"),
    F.max("dias_com_dados").alias("max_dias"),
    F.avg("dias_com_dados").alias("avg_dias"),
    F.stddev("dias_com_dados").alias("std_dias")
).collect()[0]

print("ğŸ“… DISTRIBUIÃ‡ÃƒO DE DIAS POR FILIAL E SKU")
print("=" * 50)
print(f"ğŸ“Š MÃ­nimo de dias por filial/SKU: {days_stats['min_dias']}")
print(f"ğŸ“Š MÃ¡ximo de dias por filial/SKU: {days_stats['max_dias']}")
print(f"ğŸ“Š MÃ©dia de dias por filial/SKU: {days_stats['avg_dias']:.2f}")
print(f"ğŸ“Š Desvio padrÃ£o: {days_stats['std_dias']:.2f}" if days_stats['std_dias'] else "ğŸ“Š Desvio padrÃ£o: N/A")

# Mostrar top 10 combinaÃ§Ãµes filial/SKU com mais dias
print("\nğŸ† TOP 10 - Filiais/SKUs com mais dias de dados:")
display(days_per_filial_sku.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Quantidade de SKUs por Filial

# COMMAND ----------

# Quantidade de SKUs por filial
skus_per_filial = df_merecimento.groupBy("CdFilial").agg(
    F.countDistinct("CdSku").alias("skus_por_filial")
).orderBy("skus_por_filial", ascending=False)

# EstatÃ­sticas da distribuiÃ§Ã£o
skus_stats = skus_per_filial.agg(
    F.min("skus_por_filial").alias("min_skus"),
    F.max("skus_por_filial").alias("max_skus"),
    F.avg("skus_por_filial").alias("avg_skus"),
    F.stddev("skus_por_filial").alias("std_skus")
).collect()[0]

print("ğŸª QUANTIDADE DE SKUs POR FILIAL")
print("=" * 50)
print(f"ğŸ“¦ MÃ­nimo de SKUs por filial: {skus_stats['min_skus']}")
print(f"ğŸ“¦ MÃ¡ximo de SKUs por filial: {skus_stats['max_skus']}")
print(f"ğŸ“¦ MÃ©dia de SKUs por filial: {skus_stats['avg_skus']:.2f}")
print(f"ğŸ“¦ Desvio padrÃ£o: {skus_stats['std_skus']:.2f}" if skus_stats['std_skus'] else "ğŸ“¦ Desvio padrÃ£o: N/A")

# Mostrar top 10 filiais com mais SKUs
print("\nğŸ† TOP 10 - Filiais com mais SKUs:")
display(skus_per_filial.limit(10))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. AnÃ¡lise de MÃ©tricas de NegÃ³cio

# COMMAND ----------

# MÃ©tricas de negÃ³cio
business_metrics = df_merecimento.agg(
    F.sum("EstoqueLoja").alias("total_estoque"),
    F.sum("Receita").alias("total_receita"),
    F.sum("QtMercadoria").alias("total_vendas"),
    F.sum("FlagRuptura").alias("total_rupturas"),
    F.sum("ReceitaPerdidaRuptura").alias("receita_perdida_total")
).collect()[0]

print("ğŸ’° ANÃLISE DE MÃ‰TRICAS DE NEGÃ“CIO")
print("=" * 50)
print(f"ğŸ“¦ Total de estoque: {business_metrics['total_estoque']:,}")
print(f"ğŸ’° Total de receita: R$ {business_metrics['total_receita']:,.2f}")
print(f"ğŸ›’ Total de vendas: {business_metrics['total_vendas']:,}")
print(f"âš ï¸ Total de rupturas: {business_metrics['total_rupturas']:,}")
print(f"ğŸ’¸ Receita perdida por ruptura: R$ {business_metrics['receita_perdida_total']:,.2f}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. VerificaÃ§Ãµes de Qualidade

# COMMAND ----------

print("ğŸ” VERIFICAÃ‡Ã•ES DE QUALIDADE")
print("=" * 50)

# Verificar valores negativos
negative_estoque = df_merecimento.filter(F.col("EstoqueLoja") < 0).count()
negative_receita = df_merecimento.filter(F.col("Receita") < 0).count()
negative_vendas = df_merecimento.filter(F.col("QtMercadoria") < 0).count()

print(f"âœ… Estoque negativo: {negative_estoque} registros")
print(f"âœ… Receita negativa: {negative_receita} registros")
print(f"âœ… Vendas negativas: {negative_vendas} registros")

# Verificar consistÃªncia de datas
invalid_dates = df_merecimento.filter(
    (F.col("DtAtual").isNull()) | 
    (F.col("year_month").isNull())
).count()

print(f"âœ… Datas invÃ¡lidas: {invalid_dates} registros")

# Verificar mÃ©dias mÃ³veis
invalid_media = df_merecimento.filter(
    (F.col("Media90_Receita_venda_estq") < 0) |
    (F.col("Media90_Qt_venda_estq") < 0)
).count()

print(f"âœ… MÃ©dias mÃ³veis invÃ¡lidas: {invalid_media} registros")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. AnÃ¡lise de Rupturas

# COMMAND ----------

# AnÃ¡lise detalhada de rupturas
ruptura_analysis = df_merecimento.filter(F.col("FlagRuptura") == 1).agg(
    F.count("*").alias("total_rupturas"),
    F.sum("deltaRuptura").alias("total_delta_ruptura"),
    F.sum("ReceitaPerdidaRuptura").alias("total_receita_perdida"),
    F.avg("deltaRuptura").alias("media_delta_ruptura"),
    F.avg("ReceitaPerdidaRuptura").alias("media_receita_perdida")
).collect()[0]

print("âš ï¸ ANÃLISE DE RUPTURAS")
print("=" * 50)
print(f"ğŸ“Š Total de rupturas: {ruptura_analysis['total_rupturas']:,}")
print(f"ğŸ“Š Total de delta de ruptura: {ruptura_analysis['total_delta_ruptura']:,.0f}")
print(f"ğŸ’° Total de receita perdida: R$ {ruptura_analysis['total_receita_perdida']:,.2f}")
print(f"ğŸ“Š MÃ©dia de delta de ruptura: {ruptura_analysis['media_delta_ruptura']:,.2f}")
print(f"ğŸ’° MÃ©dia de receita perdida: R$ {ruptura_analysis['media_receita_perdida']:,.2f}")

# Top 10 rupturas por receita perdida
print("\nğŸ† TOP 10 - Rupturas com maior receita perdida:")
top_rupturas = df_merecimento.filter(F.col("FlagRuptura") == 1) \
    .select("DtAtual", "CdFilial", "CdSku", "DsSku", "EstoqueLoja", 
            "Media90_Qt_venda_estq", "deltaRuptura", "ReceitaPerdidaRuptura") \
    .orderBy(F.col("ReceitaPerdidaRuptura").desc()) \
    .limit(10)

display(top_rupturas)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 9. DistribuiÃ§Ã£o por Setor e Curva

# COMMAND ----------

# DistribuiÃ§Ã£o por setor
setor_distribution = df_merecimento.groupBy("DsSetor").agg(
    F.count("*").alias("total_registros"),
    F.countDistinct("CdFilial").alias("filiais_distintas"),
    F.countDistinct("CdSku").alias("skus_distintos"),
    F.sum("EstoqueLoja").alias("total_estoque"),
    F.sum("Receita").alias("total_receita")
).orderBy("total_registros", ascending=False)

print("ğŸ­ DISTRIBUIÃ‡ÃƒO POR SETOR")
print("=" * 50)
display(setor_distribution)

# DistribuiÃ§Ã£o por curva
curva_distribution = df_merecimento.groupBy("DsCurva").agg(
    F.count("*").alias("total_registros"),
    F.countDistinct("CdFilial").alias("filiais_distintas"),
    F.countDistinct("CdSku").alias("skus_distintos"),
    F.sum("EstoqueLoja").alias("total_estoque"),
    F.sum("Receita").alias("total_receita")
).orderBy("total_registros", ascending=False)

print("ğŸ“Š DISTRIBUIÃ‡ÃƒO POR CURVA")
print("=" * 50)
display(curva_distribution)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 10. Resumo Executivo

# COMMAND ----------

# Calcular score de qualidade (0-100)
quality_score = 100

# Penalizar por campos nulos
total_null_fields = sum(1 for col_data in null_counts.values() if col_data["count"] > 0)
if total_null_fields > 0:
    quality_score -= min(20, total_null_fields * 2)

# Penalizar por valores negativos
total_negative = negative_estoque + negative_receita + negative_vendas
if total_negative > 0:
    quality_score -= min(15, total_negative * 3)

# Penalizar por inconsistÃªncias de data
if invalid_dates > 0:
    quality_score -= min(10, invalid_dates * 2)

print("ğŸ“‹ RESUMO EXECUTIVO")
print("=" * 50)

if quality_score >= 90:
    status = "ğŸŸ¢ EXCELENTE"
elif quality_score >= 80:
    status = "ğŸŸ¡ BOM"
elif quality_score >= 70:
    status = "ğŸŸ  REGULAR"
else:
    status = "ğŸ”´ ATENÃ‡ÃƒO NECESSÃRIA"

print(f"ğŸ“Š Score de Qualidade: {quality_score}/100 - {status}")
print(f"ğŸ“ˆ Total de registros vÃ¡lidos: {total_rows:,}")
print(f"ğŸª Cobertura de filiais: {distinct_counts['filiais_distintas']} filiais")
print(f"ğŸ“¦ Cobertura de SKUs: {distinct_counts['skus_distintos']} produtos")
print(f"ğŸ“… PerÃ­odo analisado: {date_range['data_min']} a {date_range['data_max']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ğŸ“Š RELATÃ“RIO CONCLUÃDO
# MAGIC 
# MAGIC Este relatÃ³rio fornece uma visÃ£o abrangente da qualidade dos dados da matriz de merecimento.
# MAGIC 
# MAGIC **PrÃ³ximos passos**:
# MAGIC 1. Analisar os nÃºmeros apresentados
# MAGIC 2. Verificar se fazem sentido para o negÃ³cio
# MAGIC 3. Definir balizamento para validaÃ§Ãµes automÃ¡ticas
# MAGIC 4. Ajustar thresholds conforme necessÃ¡rio
# MAGIC 
# MAGIC **Arquivos gerados**: RelatÃ³rio visual no notebook
# MAGIC **Score de qualidade**: {quality_score}/100
