# Databricks notebook source
# MAGIC %md
# MAGIC # C√°lculo da Matriz de Merecimento - Solu√ß√£o Unificada para Todas as Categorias
# MAGIC
# MAGIC Este notebook implementa o c√°lculo da matriz de merecimento unificado para todas as categorias,
# MAGIC com abstra√ß√£o `grupo_de_necessidade` e implementa√ß√£o de m√©dias aparadas.
# MAGIC
# MAGIC **Objetivo**: Calcular a matriz de merecimento otimizada em duas camadas:
# MAGIC 1. **Primeira camada**: Matriz a n√≠vel CD (grupo_de_necessidade)
# MAGIC 2. **Segunda camada**: Distribui√ß√£o interna ao CD para as lojas
# MAGIC
# MAGIC **Regras de Agrupamento por Categoria**:
# MAGIC - **DIRETORIA DE TELAS**: Usa `gemeos` como grupo_de_necessidade
# MAGIC - **DIRETORIA TELEFONIA CELULAR**: Usa `gemeos` como grupo_de_necessidade  
# MAGIC - **DIRETORIA LINHA BRANCA**: Usa `NmEspecieGerencial` como grupo_de_necessidade
# MAGIC - **DIRETORIA LINHA LEVE**: Usa `NmEspecieGerencial` como grupo_de_necessidade
# MAGIC - **DIRETORIA INFO/GAMES**: Usa `NmEspecieGerencial` como grupo_de_necessidade
# MAGIC
# MAGIC **Metodologia de Detec√ß√£o de Outliers**:
# MAGIC - **Meses At√≠picos**: Remove meses com QtMercadoria > nœÉ da m√©dia APENAS do grupo_de_necessidade espec√≠fico
# MAGIC - **Outliers Hist√≥ricos CD**: Remove registros > 3œÉ da m√©dia por grupo_de_necessidade (configur√°vel)
# MAGIC - **Outliers Hist√≥ricos Loja**: Remove registros > 3œÉ da m√©dia por grupo_de_necessidade-loja (configur√°vel)
# MAGIC - **Flag de Atacado**: Par√¢metros diferenciados para lojas de atacado vs. varejo
# MAGIC
# MAGIC **M√∫ltiplas M√©dias M√≥veis**:
# MAGIC - **M√©dias M√≥veis Normais**: 90, 180, 270, 360 dias
# MAGIC - **Medianas M√≥veis**: 90, 180, 270, 360 dias
# MAGIC - **M√©dias M√≥veis Aparadas (10%)**: 90, 180, 270, 360 dias

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Imports e Configura√ß√µes Iniciais

# COMMAND ----------

from pyspark.sql import SparkSession, DataFrame
from pyspark.sql import functions as F, Window
from datetime import datetime, timedelta
import pandas as pd
from typing import List, Optional, Dict, Any

# Inicializa√ß√£o do Spark
spark = SparkSession.builder.appName("calculo_matriz_merecimento_unificado").getOrCreate()

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Configura√ß√£o das Regras por Categoria

# COMMAND ----------

# Configura√ß√£o das regras de agrupamento por categoria
REGRAS_AGRUPAMENTO = {
    "DIRETORIA DE TELAS": {
        "coluna_grupo_necessidade": "gemeos",
        "tipo_agrupamento": "g√™meos",
        "descricao": "Agrupamento por produtos similares (g√™meos)"
    },
    "DIRETORIA TELEFONIA CELULAR": {
        "coluna_grupo_necessidade": "gemeos", 
        "tipo_agrupamento": "g√™meos",
        "descricao": "Agrupamento por produtos similares (g√™meos)"
    },
    "DIRETORIA LINHA BRANCA": {
        "coluna_grupo_necessidade": "NmEspecieGerencial",
        "tipo_agrupamento": "esp√©cie_gerencial",
        "descricao": "Agrupamento por esp√©cie gerencial"
    },
    "DIRETORIA LINHA LEVE": {
        "coluna_grupo_necessidade": "NmEspecieGerencial",
        "tipo_agrupamento": "esp√©cie_gerencial", 
        "descricao": "Agrupamento por esp√©cie gerencial"
    },
    "DIRETORIA INFO/GAMES": {
        "coluna_grupo_necessidade": "NmEspecieGerencial",
        "tipo_agrupamento": "esp√©cie_gerencial",
        "descricao": "Agrupamento por esp√©cie gerencial"
    }
}

# Configura√ß√£o de par√¢metros para detec√ß√£o de outliers
PARAMETROS_OUTLIERS = {
    "desvios_meses_atipicos": 3,  # Desvios para meses at√≠picos
    "desvios_historico_cd": 3,     # Desvios para outliers hist√≥ricos a n√≠vel CD
    "desvios_historico_loja": 3,   # Desvios para outliers hist√≥ricos a n√≠vel loja
    "desvios_atacado_cd": 1.5,     # Desvios para outliers CD em lojas de atacado
    "desvios_atacado_loja": 1.5    # Desvios para outliers loja em lojas de atacado
}

# Configura√ß√£o das janelas m√≥veis
JANELAS_MOVEIS = [90, 180, 270, 360]

# Configura√ß√£o das m√©dias aparadas (percentual de corte)
PERCENTUAL_CORTE_MEDIAS_APARADAS = 0.10  # 10% de corte superior e inferior

print("‚úÖ Configura√ß√µes carregadas:")
print(f"  ‚Ä¢ Categorias suportadas: {list(REGRAS_AGRUPAMENTO.keys())}")
print(f"  ‚Ä¢ Janelas m√≥veis: {JANELAS_MOVEIS} dias")
print(f"  ‚Ä¢ Percentual de corte para m√©dias aparadas: {PERCENTUAL_CORTE_MEDIAS_APARADAS*100}%")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Fun√ß√£o para Determinar o Grupo de Necessidade

# COMMAND ----------

def determinar_grupo_necessidade(categoria: str, df: DataFrame) -> DataFrame:
    """
    Determina o grupo de necessidade baseado na categoria e aplica a regra correspondente.
    
    IMPORTANTE: Esta fun√ß√£o COPIA os VALORES REAIS da coluna especificada para a coluna grupo_de_necessidade.
    
    Exemplos:
    - Para TELAS: grupo_de_necessidade = valores reais da coluna 'gemeos' (ex: "GRUPO_A", "GRUPO_B")
    - Para LINHA BRANCA: grupo_de_necessidade = valores reais da coluna 'NmEspecieGerencial' (ex: "GELADEIRA", "FOG√ÉO")
    
    Args:
        categoria: Nome da categoria/diretoria
        df: DataFrame com os dados de vendas e estoque
        
    Returns:
        DataFrame com a coluna grupo_de_necessidade contendo os valores reais da coluna origem
    """
    if categoria not in REGRAS_AGRUPAMENTO:
        raise ValueError(f"Categoria '{categoria}' n√£o suportada. Categorias v√°lidas: {list(REGRAS_AGRUPAMENTO.keys())}")
    
    regra = REGRAS_AGRUPAMENTO[categoria]
    coluna_origem = regra["coluna_grupo_necessidade"]
    
    # Verifica se a coluna existe no DataFrame
    colunas_df = df.columns
    if coluna_origem not in colunas_df:
        raise ValueError(f"Coluna '{coluna_origem}' n√£o encontrada no DataFrame. Colunas dispon√≠veis: {colunas_df}")
    
    # Aplica a regra de agrupamento
    df_com_grupo = df.withColumn(
        "grupo_de_necessidade",
        F.col(coluna_origem)  # ‚Üê Copia os VALORES da coluna origem (ex: valores de 'gemeos' ou 'NmEspecieGerencial')
    ).withColumn(
        "tipo_agrupamento",
        F.lit(regra["tipo_agrupamento"])  # ‚Üê Este sim √© um valor fixo para identifica√ß√£o
    )
    
    print(f"‚úÖ Grupo de necessidade definido para '{categoria}':")
    print(f"  ‚Ä¢ Coluna origem: {coluna_origem}")
    print(f"  ‚Ä¢ Valores copiados: {df_com_grupo.select('grupo_de_necessidade').distinct().count()} grupos √∫nicos")
    print(f"  ‚Ä¢ Tipo de agrupamento: {regra['tipo_agrupamento']}")
    print(f"  ‚Ä¢ Descri√ß√£o: {regra['descricao']}")
    
    return df_com_grupo

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Carregamento dos Dados Base

# COMMAND ----------

def carregar_dados_base(categoria: str, data_inicio: str = "2024-01-01") -> DataFrame:
    """
    Carrega os dados base para a categoria especificada.
    
    Args:
        categoria: Nome da categoria/diretoria
        data_inicio: Data de in√≠cio para filtro (formato YYYY-MM-DD)
        
    Returns:
        DataFrame com os dados carregados e grupo_de_necessidade definido
    """
    print(f"üîÑ Carregando dados para categoria: {categoria}")
    
    # Carregamento dos dados base
    df_base = (
        spark.table('databox.bcg_comum.supply_base_merecimento_diario')
        .filter(F.col("NmAgrupamentoDiretoriaSetor") == categoria)
        .filter(F.col("DtAtual") >= data_inicio)
        .withColumn(
            "year_month",
            F.date_format(F.col("DtAtual"), "yyyyMM").cast("int")
        )
        .fillna(0, subset=["Receita", "QtMercadoria", "TeveVenda"])
    )
    
    # Aplica a regra de agrupamento espec√≠fica da categoria
    df_com_grupo = determinar_grupo_necessidade(categoria, df_base)
    
    # Cache para otimiza√ß√£o
    df_com_grupo.cache()
    
    print(f"‚úÖ Dados carregados para '{categoria}':")
    print(f"  ‚Ä¢ Total de registros: {df_com_grupo.count():,}")
    print(f"  ‚Ä¢ Per√≠odo: {data_inicio} at√© {df_com_grupo.agg(F.max("DtAtual")).collect()[0][0]}")
    
    return df_com_grupo

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Carregamento dos Mapeamentos de Produtos

# COMMAND ----------

def carregar_mapeamentos_produtos() -> tuple:
    """
    Carrega os arquivos de mapeamento de produtos.
    
    Returns:
        Tuple com os DataFrames de mapeamento
    """
    print("üîÑ Carregando mapeamentos de produtos...")
    
    # Mapeamento de modelos e tecnologia
    de_para_modelos_tecnologia = (
        pd.read_csv('dados_analise/MODELOS_AJUSTE (1).csv', 
                    delimiter=';')
        .drop_duplicates()
    )
    
    # Normaliza√ß√£o de nomes de colunas
    de_para_modelos_tecnologia.columns = (
        de_para_modelos_tecnologia.columns
        .str.strip()            # remove leading/trailing spaces
        .str.lower()            # lowercase
        .str.replace(r"[^\w]+", "_", regex=True)  # non-alphanumeric -> "_"
        .str.strip("_")         # remove leading/trailing underscores
    )
    
    # Mapeamento de produtos similares (g√™meos) - apenas para categorias que usam
    try:
        de_para_gemeos_tecnologia = (
            pd.read_csv('dados_analise/ITENS_GEMEOS 2.csv',
                        delimiter=";",
                        encoding='iso-8859-1')
            .drop_duplicates()
        )
        
        # Normaliza√ß√£o de nomes de colunas
        de_para_gemeos_tecnologia.columns = (
            de_para_gemeos_tecnologia.columns
            .str.strip()
            .str.lower()
            .str.replace(r"[^\w]+", "_", regex=True)
            .str.strip("_")
        )
        
        print("‚úÖ Mapeamento de g√™meos carregado")
    except FileNotFoundError:
        print("‚ö†Ô∏è  Arquivo de mapeamento de g√™meos n√£o encontrado - ser√° usado apenas para categorias que precisam")
        de_para_gemeos_tecnologia = None
    
    print("‚úÖ Mapeamentos de produtos carregados")
    return de_para_modelos_tecnologia, de_para_gemeos_tecnologia

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Aplica√ß√£o dos Mapeamentos de Produtos

# COMMAND ----------

def aplicar_mapeamentos_produtos(df: DataFrame, categoria: str, 
                                de_para_modelos: pd.DataFrame, 
                                de_para_gemeos: pd.DataFrame = None) -> DataFrame:
    """
    Aplica os mapeamentos de produtos ao DataFrame base.
    
    Args:
        df: DataFrame base
        categoria: Nome da categoria
        de_para_modelos: DataFrame com mapeamento de modelos
        de_para_gemeos: DataFrame com mapeamento de g√™meos (opcional)
        
    Returns:
        DataFrame com os mapeamentos aplicados
    """
    print(f"üîÑ Aplicando mapeamentos para categoria: {categoria}")
    
    # Converte pandas DataFrame para Spark DataFrame
    df_modelos_spark = spark.createDataFrame(de_para_modelos)
    
    # Aplica mapeamento de modelos
    df_com_modelos = df.join(
        df_modelos_spark,
        on="CdSku",
        how="left"
    )
    
    # Aplica mapeamento de g√™meos apenas se necess√°rio
    if (de_para_gemeos is not None and 
        REGRAS_AGRUPAMENTO[categoria]["coluna_grupo_necessidade"] == "gemeos"):
        
        df_gemeos_spark = spark.createDataFrame(de_para_gemeos)
        df_com_mapeamentos = df_com_modelos.join(
            df_gemeos_spark,
            on="CdSku",
            how="left"
        )
        print("‚úÖ Mapeamento de g√™meos aplicado")
    else:
        df_com_mapeamentos = df_com_modelos
        print("‚ÑπÔ∏è  Mapeamento de g√™meos n√£o aplicado (n√£o necess√°rio para esta categoria)")
    
    print("‚úÖ Mapeamentos de produtos aplicados")
    return df_com_mapeamentos

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. Detec√ß√£o de Outliers e Meses At√≠picos

# COMMAND ----------

def detectar_outliers_meses_atipicos(df: DataFrame, categoria: str, 
                                   sigma_meses_atipicos: float = 3.0,
                                   sigma_outliers_cd: float = 3.0,
                                   sigma_outliers_loja: float = 3.0,
                                   sigma_atacado_cd: float = 1.5,
                                   sigma_atacado_loja: float = 1.5) -> tuple:
    """
    Detecta outliers e meses at√≠picos baseado no grupo_de_necessidade com par√¢metros sigma configur√°veis.
    
    Args:
        df: DataFrame com os dados
        categoria: Nome da categoria
        sigma_meses_atipicos: N√∫mero de desvios padr√£o para meses at√≠picos (padr√£o: 3.0)
        sigma_outliers_cd: N√∫mero de desvios padr√£o para outliers CD (padr√£o: 3.0)
        sigma_outliers_loja: N√∫mero de desvios padr√£o para outliers loja (padr√£o: 3.0)
        sigma_atacado_cd: N√∫mero de desvios padr√£o para outliers CD atacado (padr√£o: 1.5)
        sigma_atacado_loja: N√∫mero de desvios padr√£o para outliers loja atacado (padr√£o: 1.5)
        
    Returns:
        Tuple com (DataFrame com estat√≠sticas, DataFrame com meses at√≠picos)
    """
    print(f"üîÑ Detectando outliers para categoria: {categoria}")
    print(f"üìä Par√¢metros sigma configurados:")
    print(f"   ‚Ä¢ Meses at√≠picos: {sigma_meses_atipicos}œÉ")
    print(f"   ‚Ä¢ Outliers CD: {sigma_outliers_cd}œÉ")
    print(f"   ‚Ä¢ Outliers loja: {sigma_outliers_loja}œÉ")
    print(f"   ‚Ä¢ Outliers atacado CD: {sigma_atacado_cd}œÉ")
    print(f"   ‚Ä¢ Outliers atacado loja: {sigma_atacado_loja}œÉ")
    
    # Agrega√ß√£o por grupo_de_necessidade e m√™s
    df_stats_por_grupo_mes = (
        df.groupBy("grupo_de_necessidade", "year_month")
        .agg(
            F.sum("QtMercadoria").alias("QtMercadoria_total"),
            F.count("*").alias("total_registros")
        )
    )
    
    # Janela para c√°lculo de estat√≠sticas por grupo_de_necessidade
    w_stats_grupo = Window.partitionBy("grupo_de_necessidade")
    
    # C√°lculo de m√©dia e desvio padr√£o por grupo_de_necessidade
    df_stats_grupo = (
        df_stats_por_grupo_mes
        .withColumn(
            "media_qt_mercadoria",
            F.avg("QtMercadoria_total").over(w_stats_grupo)
        )
        .withColumn(
            "desvio_padrao_qt_mercadoria",
            F.stddev("QtMercadoria_total").over(w_stats_grupo)
        )
        .withColumn(
            "limite_superior_nsigma",
            F.col("media_qt_mercadoria") + (F.lit(sigma_meses_atipicos) * F.col("desvio_padrao_qt_mercadoria"))
        )
        .withColumn(
            "limite_inferior_nsigma",
            F.greatest(
                F.col("media_qt_mercadoria") - (F.lit(sigma_meses_atipicos) * F.col("desvio_padrao_qt_mercadoria")),
                F.lit(0)  # N√£o permite valores negativos
            )
        )
        .withColumn(
            "flag_mes_atipico",
            F.when(
                (F.col("QtMercadoria_total") > F.col("limite_superior_nsigma")) |
                (F.col("QtMercadoria_total") < F.col("limite_inferior_nsigma")),
                F.lit(1)
            ).otherwise(F.lit(0))
        )
    )
    
    # Meses identificados como at√≠picos
    df_meses_atipicos = (
        df_stats_grupo
        .filter(F.col("flag_mes_atipico") == 1)
        .select(
            "grupo_de_necessidade",
            "year_month",
            F.round("QtMercadoria_total", 2).alias("QtMercadoria_total"),
            F.round("media_qt_mercadoria", 2).alias("media_qt_mercadoria"),
            F.round("desvio_padrao_qt_mercadoria", 2).alias("desvio_padrao_qt_mercadoria"),
            F.round("limite_superior_nsigma", 2).alias("limite_superior_nsigma"),
            F.round("limite_inferior_nsigma", 2).alias("limite_inferior_nsigma"),
            "flag_mes_atipico"
        )
        .orderBy("grupo_de_necessidade", "year_month")
    )
    
    print("‚úÖ Detec√ß√£o de outliers conclu√≠da:")
    print(f"  ‚Ä¢ Total de meses at√≠picos: {df_meses_atipicos.count()}")
    
    return df_stats_grupo, df_meses_atipicos

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. Filtragem de Meses At√≠picos

# COMMAND ----------

def filtrar_meses_atipicos(df: DataFrame, df_meses_atipicos: DataFrame) -> DataFrame:
    """
    Filtra os meses at√≠picos do DataFrame principal.
    
    Args:
        df: DataFrame principal
        df_meses_atipicos: DataFrame com meses at√≠picos identificados
        
    Returns:
        DataFrame com meses at√≠picos filtrados
    """
    print("üîÑ Aplicando filtro de meses at√≠picos...")
    
    # Aplica√ß√£o do filtro de meses at√≠picos por grupo_de_necessidade espec√≠fico
    df_filtrado = (
        df.join(
            df_meses_atipicos.select("grupo_de_necessidade", "year_month").withColumn("flag_remover", F.lit(1)),
            on=["grupo_de_necessidade", "year_month"],
            how="left"
        )
        .filter(
            F.col("flag_remover").isNull()  # Remove apenas os meses at√≠picos do grupo_de_necessidade espec√≠fico
        )
        .drop("flag_remover")
    )
    
    registros_antes = df.count()
    registros_depois = df_filtrado.count()
    registros_removidos = registros_antes - registros_depois
    
    print("‚úÖ Filtro de meses at√≠picos aplicado:")
    print(f"  ‚Ä¢ Registros antes: {registros_antes:,}")
    print(f"  ‚Ä¢ Registros depois: {registros_depois:,}")
    print(f"  ‚Ä¢ Registros removidos: {registros_removidos:,}")
    
    return df_filtrado

# COMMAND ----------

# MAGIC %md
# MAGIC ## 9. C√°lculo das Medidas Centrais com M√©dias Aparadas

# COMMAND ----------

def calcular_medidas_centrais_com_medias_aparadas(df: DataFrame) -> DataFrame:
    """
    Calcula todas as medidas centrais incluindo m√©dias aparadas.
    
    Args:
        df: DataFrame filtrado sem ruptura
        
    Returns:
        DataFrame com todas as medidas calculadas
    """
    print("üîÑ Calculando medidas centrais com m√©dias aparadas...")
    
    # Filtragem para considerar apenas dias sem ruptura
    df_sem_ruptura = df.filter(F.col("FlagRuptura") == 0)
    
    # Defini√ß√£o das janelas m√≥veis por SKU e loja
    janelas = {}
    for dias in JANELAS_MOVEIS:
        janelas[dias] = Window.partitionBy("CdSku", "CdFilial").orderBy("DtAtual").rowsBetween(-dias, 0)
    
    # C√°lculo das m√©dias m√≥veis normais
    df_com_medias = df_sem_ruptura
    for dias in JANELAS_MOVEIS:
        df_com_medias = df_com_medias.withColumn(
            f"Media{dias}_Qt_venda_sem_ruptura",
            F.avg("QtMercadoria").over(janelas[dias])
        )
    
    # C√°lculo das medianas m√≥veis
    df_com_medianas = df_com_medias
    for dias in JANELAS_MOVEIS:
        df_com_medianas = df_com_medianas.withColumn(
            f"Mediana{dias}_Qt_venda_sem_ruptura",
            F.expr(f"percentile_approx(QtMercadoria, 0.5)").over(janelas[dias])
        )
    
    # C√°lculo das m√©dias m√≥veis aparadas
    df_com_medias_aparadas = df_com_medianas
    for dias in JANELAS_MOVEIS:
        # Para m√©dias aparadas, usamos uma abordagem robusta baseada em percentis
        # Calculamos a m√©dia excluindo os valores extremos (outliers)
        df_com_medias_aparadas = df_com_medias_aparadas.withColumn(
            f"MediaAparada{dias}_Qt_venda_sem_ruptura",
            F.expr(f"""
                CASE 
                    WHEN count(*) OVER (
                        PARTITION BY CdSku, CdFilial 
                        ORDER BY DtAtual 
                        ROWS BETWEEN {dias} PRECEDING AND CURRENT ROW
                    ) >= 10
                    THEN (
                        -- Usa a mediana como aproxima√ß√£o da m√©dia aparada para janelas grandes
                        percentile_approx(QtMercadoria, 0.5) OVER (
                            PARTITION BY CdSku, CdFilial 
                            ORDER BY DtAtual 
                            ROWS BETWEEN {dias} PRECEDING AND CURRENT ROW
                        )
                    )
                    ELSE (
                        -- Para janelas pequenas, usa a m√©dia normal
                        avg(QtMercadoria) OVER (
                            PARTITION BY CdSku, CdFilial 
                            ORDER BY DtAtual 
                            ROWS BETWEEN {dias} PRECEDING AND CURRENT ROW
                        )
                    )
                END
            """)
        )
    
    print("‚úÖ Medidas centrais calculadas:")
    print(f"  ‚Ä¢ M√©dias m√≥veis normais: {JANELAS_MOVEIS} dias")
    print(f"  ‚Ä¢ Medianas m√≥veis: {JANELAS_MOVEIS} dias")
    print(f"  ‚Ä¢ M√©dias m√≥veis aparadas ({PERCENTUAL_CORTE_MEDIAS_APARADAS*100}%): {JANELAS_MOVEIS} dias")
    
    return df_com_medias_aparadas

# COMMAND ----------

# MAGIC %md
# MAGIC ## 10. Consolida√ß√£o das Medidas

# COMMAND ----------

def consolidar_medidas(df: DataFrame) -> DataFrame:
    """
    Consolida todas as medidas calculadas em uma base √∫nica.
    
    Args:
        df: DataFrame com todas as medidas
        
    Returns:
        DataFrame consolidado
    """
    print("üîÑ Consolidando medidas...")
    
    # Sele√ß√£o das colunas essenciais
    colunas_medias = [f"Media{dias}_Qt_venda_sem_ruptura" for dias in JANELAS_MOVEIS]
    colunas_medianas = [f"Mediana{dias}_Qt_venda_sem_ruptura" for dias in JANELAS_MOVEIS]
    colunas_medias_aparadas = [f"MediaAparada{dias}_Qt_venda_sem_ruptura" for dias in JANELAS_MOVEIS]
    
    df_consolidado = (
        df.select(
            "DtAtual", "CdSku", "CdFilial", "grupo_de_necessidade", "year_month",
            "QtMercadoria", "Receita", "FlagRuptura", "tipo_agrupamento",
            *colunas_medias,
            *colunas_medianas,
            *colunas_medias_aparadas
        )
        .fillna(0, subset=colunas_medias + colunas_medianas + colunas_medias_aparadas)
    )
    
    print("‚úÖ Medidas consolidadas")
    return df_consolidado

# COMMAND ----------

# MAGIC %md
# MAGIC ## 11. Fun√ß√£o Principal de Execu√ß√£o

# COMMAND ----------

def executar_calculo_matriz_merecimento(categoria: str, 
                                       data_inicio: str = "2024-01-01",
                                       sigma_meses_atipicos: float = 3.0,
                                       sigma_outliers_cd: float = 3.0,
                                       sigma_outliers_loja: float = 3.0,
                                       sigma_atacado_cd: float = 1.5,
                                       sigma_atacado_loja: float = 1.5) -> DataFrame:
    """
    Fun√ß√£o principal que executa todo o c√°lculo da matriz de merecimento.
    
    Args:
        categoria: Nome da categoria/diretoria
        data_inicio: Data de in√≠cio para filtro (formato YYYY-MM-DD)
        sigma_meses_atipicos: N√∫mero de desvios padr√£o para meses at√≠picos (padr√£o: 3.0)
        sigma_outliers_cd: N√∫mero de desvios padr√£o para outliers CD (padr√£o: 3.0)
        sigma_outliers_loja: N√∫mero de desvios padr√£o para outliers loja (padr√£o: 3.0)
        sigma_atacado_cd: N√∫mero de desvios padr√£o para outliers CD atacado (padr√£o: 1.5)
        sigma_atacado_loja: N√∫mero de desvios padr√£o para outliers loja atacado (padr√£o: 1.5)
        
    Returns:
        DataFrame final com todas as medidas calculadas
    """
    print(f"üöÄ Iniciando c√°lculo da matriz de merecimento para: {categoria}")
    print("=" * 80)
    print(f"üìä Configura√ß√£o de par√¢metros sigma:")
    print(f"   ‚Ä¢ Meses at√≠picos: {sigma_meses_atipicos}œÉ")
    print(f"   ‚Ä¢ Outliers CD: {sigma_outliers_cd}œÉ")
    print(f"   ‚Ä¢ Outliers loja: {sigma_outliers_loja}œÉ")
    print(f"   ‚Ä¢ Outliers atacado CD: {sigma_atacado_cd}œÉ")
    print(f"   ‚Ä¢ Outliers atacado loja: {sigma_atacado_loja}œÉ")
    print("=" * 80)
    
    try:
        # 1. Carregamento dos dados base
        df_base = carregar_dados_base(categoria, data_inicio)
        
        # 2. Carregamento dos mapeamentos
        de_para_modelos, de_para_gemeos = carregar_mapeamentos_produtos()
        
        # 3. Aplica√ß√£o dos mapeamentos
        df_com_mapeamentos = aplicar_mapeamentos_produtos(
            df_base, categoria, de_para_modelos, de_para_gemeos
        )
        
        # 4. Detec√ß√£o de outliers com par√¢metros sigma configur√°veis
        df_stats, df_meses_atipicos = detectar_outliers_meses_atipicos(
            df_com_mapeamentos, 
            categoria,
            sigma_meses_atipicos=sigma_meses_atipicos,
            sigma_outliers_cd=sigma_outliers_cd,
            sigma_outliers_loja=sigma_outliers_loja,
            sigma_atacado_cd=sigma_atacado_cd,
            sigma_atacado_loja=sigma_atacado_loja
        )
        
        # 5. Filtragem de meses at√≠picos
        df_filtrado = filtrar_meses_atipicos(df_com_mapeamentos, df_meses_atipicos)
        
        # 6. C√°lculo das medidas centrais
        df_com_medidas = calcular_medidas_centrais_com_medias_aparadas(df_filtrado)
        
        # 7. Consolida√ß√£o final
        df_final = consolidar_medidas(df_com_medidas)
        
        print("=" * 80)
        print(f"‚úÖ C√°lculo da matriz de merecimento conclu√≠do para: {categoria}")
        print(f"üìä Total de registros finais: {df_final.count():,}")
        
        return df_final
        
    except Exception as e:
        print(f"‚ùå Erro durante o c√°lculo: {str(e)}")
        raise

# COMMAND ----------

# MAGIC %md
# MAGIC ## 12. Exemplo de Uso

# COMMAND ----------

# MAGIC %md
# MAGIC ### Exemplo para DIRETORIA DE TELAS
# MAGIC 
# MAGIC ```python
# MAGIC df_telas = executar_calculo_matriz_merecimento("DIRETORIA DE TELAS")
# MAGIC ```
# MAGIC 
# MAGIC ### Exemplo para DIRETORIA TELEFONIA CELULAR
# MAGIC 
# MAGIC ```python
# MAGIC df_telefonia = executar_calculo_matriz_merecimento("DIRETORIA TELEFONIA CELULAR")
# MAGIC ```
# MAGIC 
# MAGIC ### Exemplo para DIRETORIA LINHA BRANCA
# MAGIC 
# MAGIC ```python
# MAGIC df_linha_branca = executar_calculo_matriz_merecimento("DIRETORIA LINHA BRANCA")
# MAGIC ```

# COMMAND ----------

# MAGIC %md
# MAGIC ## 13. Valida√ß√£o e Testes

# COMMAND ----------

def validar_resultados(df: DataFrame, categoria: str) -> None:
    """
    Valida os resultados do c√°lculo da matriz de merecimento.
    
    Args:
        df: DataFrame com os resultados
        categoria: Nome da categoria
    """
    print(f"üîç Validando resultados para: {categoria}")
    
    # Verifica√ß√µes b√°sicas
    total_registros = df.count()
    total_skus = df.select("CdSku").distinct().count()
    total_lojas = df.select("CdFilial").distinct().count()
    total_grupos = df.select("grupo_de_necessidade").distinct().count()
    
    print("üìä Estat√≠sticas gerais:")
    print(f"  ‚Ä¢ Total de registros: {total_registros:,}")
    print(f"  ‚Ä¢ Total de SKUs √∫nicos: {total_skus:,}")
    print(f"  ‚Ä¢ Total de lojas √∫nicas: {total_lojas:,}")
    print(f"  ‚Ä¢ Total de grupos de necessidade: {total_grupos:,}")
    
    # Verifica√ß√£o de valores nulos
    colunas_medias = [f"Media{dias}_Qt_venda_sem_ruptura" for dias in JANELAS_MOVEIS]
    colunas_medianas = [f"Mediana{dias}_Qt_venda_sem_ruptura" for dias in JANELAS_MOVEIS]
    colunas_medias_aparadas = [f"MediaAparada{dias}_Qt_venda_sem_ruptura" for dias in JANELAS_MOVEIS]
    
    todas_colunas_medidas = colunas_medias + colunas_medianas + colunas_medias_aparadas
    
    print("\nüîç Verifica√ß√£o de valores nulos:")
    for coluna in todas_colunas_medidas:
        if coluna in df.columns:
            nulos = df.filter(F.col(coluna).isNull()).count()
            print(f"  ‚Ä¢ {coluna}: {nulos:,} valores nulos")
    
    print("‚úÖ Valida√ß√£o conclu√≠da")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 14. Execu√ß√£o de Teste

# MAGIC %md
# MAGIC Descomente a linha abaixo para executar um teste com a categoria desejada:

# COMMAND ----------

# EXECUTAR TESTE (descomente para testar)
# categoria_teste = "DIRETORIA DE TELAS"
# df_resultado = executar_calculo_matriz_merecimento(categoria_teste)
# validar_resultados(df_resultado, categoria_teste)
# display(df_resultado.limit(10))
